---
tags:
  - prob_stats1
  - chapter
date: 2024-01-29
---
[[Directory]], [[Probability and Statistics 1|Subject Directory]]

# Discrete Random Variables
## Introduction
### Example:
We consider throwing 2 independent fair dice. Here, the full sample space is 
$$
\Omega=\{ (i,\, j)\mid 1\leq i,\, j\leq 6 \}
$$
We are interested in the sum of the 2 dice. Therefore, we define a function ${} S:\Omega\to{}\{ 2,\,\dots,\,12 \} {}$ with
$$
S(i,\, j)=i+j
$$
We call $S$ a *discrete random variable*, since
- $S$ can take only a finite (or countably infinite) number of values so it is *discrete*
- The value of $S$ is random, so it is *random*
- $S$ can take different values, so it is a *variable*
We denote the event that the function $S$ attains the value $k$ by ${} S=k {}$, meaning
$$
\{ S=k \}:=\{ \omega \in \Omega\mid S(\omega)=k \}
$$
### Definition 1.1: Discrete Random Variable
Let $\Omega$ be a sample space. A *discrete random variable* is a function $X:\Omega\to{}\mathbb{R} {}$ whose image is countable.
### Definition 1.2: Probability Mass Function
Given a sample space $\Omega$, and a discrete random variable $X:\Omega\to{}\mathbb{R} {}$, then the *probability mass function* is a function ${} p_{X}:\mathbb{R}\to{}[0,\, 1] {}$ defined by
$$
p_{X}(k)=\mathbb{P}(X=k)=\mathbb{P}(\omega \in \Omega \mid X(\omega)=k)
$$
### Theorem 1.3: Properties of the Probability mass function
Let $\Omega$ be a sample space, and let $X$ be a discrete random variable, and let $p_{X} {}$ be a probability mass function. Now:
1. If ${} k \in  \im X {}$, $p_{X}\geq 0$
2. ${} \sum_{k\in \im X} p_{X}(k)=1 {}$
#### Proof:
1. 
${} p_{X}(k)=\mathbb{P}(X=k)=\mathbb{P}(\{ \omega \in  \Omega \mid X(\omega)=k \})\geq 0 {}$
2. 
We have
$$
\begin{align}
\sum_{k\in \im X} \mathbb{P}(X=k) & =\sum_{k\in \im X} \mathbb{P}(\{ \omega \in \Omega\mid X(\omega)=k \}) \\
 & =\mathbb{P}\left(\bigcup_{k\in \im X} \{ \omega \in \Omega \mid X(\omega)=k \}\right) \\
 & = \mathbb{P}(\Omega) \\
 & =1
\end{align}
$$
## Common Distributions
### Bernoulli Random Variable
This is designed to model a trial with only 2 outcomes; either success or failure. Now ${} \Omega=\{ \text{success},\, \text{failure} \} {}$, and 
$$
X(\omega)=\begin{cases}
1 &  \text{if } \omega=\text{success} \\
0 & \text{if } \omega=\text{failure}
\end{cases}
$$
and for some $0\leq p\leq 1$, we have
$$
\begin{align}
 p_{X}(0) & =1-p   \\
p_{X}(1) & =p
 \end{align}
$$
### Binomial
Designed to model a fixed number of trials where the value of interest is the number of successes. We assume that the probability of success to be fixed, and that the trials are independent.

> [!NOTE] Killing
> yous

Now we have
$$
\Omega=\{ (x_{1},\, x_{2},\,\dots,\,x_{n}) \mid x_{i} \in \{ \text{S},\, \text{F} \} \}
$$
and 
$$
X(\omega)=\#\text{ of sucessess}
$$
now there exists a ${} 0\leq p\leq 1 {}$ with $$
$$
p_{X}(k)= \binom{n}{k} \frac{k}{n}
$$