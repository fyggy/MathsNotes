---
tags:
  - linear_algebra1
  - chapter
date: 2024-01-18
---
[[Directory]], [[Linear Algebra and Geometry 2|Subject Directory]]
[[1. Intro, Eigenvectors and Eigenvalues|Last]] ;; [[Subjects/Linear Algebra and Geometry 2/3.|Next]]
# Linear Operators
Recall that a linear operator ${} T:V\to{}V {}$ is just a linear endomorphism.
## Eigenvectors and Eigenvalues
### Definition 1.1
Let ${} T:V\to{}V {}$ be a linear operator, and ${} V$ is a vector space over $\mathbb{F}$. We call $\mathbf{v}$ an *eigenvector* of $T {}$ iff 
- ${} \mathbf{v}\neq 0 {}$
- ${} T\mathbf{v}=\lambda \mathbf{v} {}$ for some ${} \lambda \in \mathbb{F} {}$
We call $\lambda {}$ the *eigenvalue associated with the eigenvector ${} \mathbf{v} {}$*. Note that we may rewrite this as
$$
\begin{align}
 T\mathbf{v}-\lambda \mathbf{v} & =0  \\
T\mathbf{v}-\lambda I\mathbf{v} & =0  
 \end{align}
$$
where ${} I$ is the identity matrix of ${} V_{}$. We factor $\mathbf{v}$ out, writing
$$
(T-\lambda I)\mathbf{v}=0\quad\Rightarrow \quad\mathbf{v} \in \ker (T-\lambda I)
$$
Conversely, if ${} \mathbf{v} \in \ker (T-\lambda I) {}$, then ${} T\mathbf{v}-\lambda I\mathbf{v}=0 {}$, so ${} T\mathbf{v}=\lambda \mathbf{v} {}$. Therefore, $\mathbf{v} {}$ is an eigenvector iff $\mathbf{v}\neq 0$ and ${} \mathbf{v} \in \ker (T-\lambda I) {}$.

We call ${} \ker (T-\lambda I) {}$ the *$\lambda$-eigenspace* of $T$, denoted $V_{\lambda} {}$. 
### Definition 1.2: Spectrum of a Linear Operator
Let $T:V\to{}V {}$ be a linear operator. The *spectrum* ${} \sigma(T)$ of $T {}$ is
$$
\sigma(T)=\{ \lambda \in \mathbb{F} \mid\lambda \text{ is an eigenvalue of } T\}
$$
#### Example:
$$
A=\begin{pmatrix}2 & \phantom{0} & \phantom{0} \\ \phantom{0} & 0 & \phantom{0} \\ \phantom{0} & \phantom{0} & 2 \end{pmatrix} 
$$
From Monday we know that $0$ and $2$ are eigenvalues of $A$. Now the eigenspaces related to these eigenvalues are
$$
V_{2}=\ker (A-2I)=\ker \begin{pmatrix}0 & 0 & 0 \\ 0 & -2 & 0 \\ 0 & 0 & 0 \end{pmatrix} =\span\{e_{1},\, e_{3}\}
$$
and
$$
V_{0}=\ker (A-0I)=\ker  \begin{pmatrix}2 & 0 & 0 \\ 0 &  0&  0\\ 0 & 0 & 2 \end{pmatrix} =\span\{e_{2}\}
$$
We now claim that there are no more eigenvalues of ${} A {}$. 
#### Proof:
Let ${} \lambda\neq 0,\, 2 {}$. Now 
$$
A-\lambda I=\begin{pmatrix}2-\lambda & 0 & 0 \\ 0 & -\lambda & 0 \\ 0 & 0 & 2-\lambda \end{pmatrix} 
$$
which has rank $3$. Therefore, $A-\lambda I {}$ is invertible. Therefore, ${} \ker (A-\lambda I)=\{ \mathbf{0} \} {}$, and so there can be no more eigenvectors, as they must be non-zero. Therefore, there are no more eigenvalues. 
## Similarity
### Definition 1.3: Similarity of Matrices
Let ${} A,\, B \in M_{n}(\mathbb{F}) {}$. We say that $A {}$ is *similar* to $B$ if there exists some ${} Q \in M_{n}(\mathbb{F}) {}$ such that:
- $Q$ is invertible
- ${} B=QAQ^{-1} {}$
and we write ${} A \simeq B {}$.
#### Remark:
We may write "similar over $\mathbb{F}$" to emphasise the base field. Also note that $Q$ is *not* unique, in general.
#### Example:
$$
A=\begin{pmatrix}1 & 0 \\ 0 & -1 \end{pmatrix} \qquad B=\begin{pmatrix}0 & 1 \\ 1 & 0 \end{pmatrix} 
$$
We see that if we take
$$
Q=\begin{pmatrix}1 & 1 \\ 1 & -1 \end{pmatrix} 
$$
We see that $Q$ is invertible, as ${} \det Q=-1-1=-2\neq 0 {}$. Now
$$
\begin{align}
BQ & = \begin{pmatrix}0 & 1 \\ 1 & 0 \end{pmatrix} \begin{pmatrix}1 & 1 \\ 1 & -1 \end{pmatrix} = \begin{pmatrix}1 & -1 \\ 1 & 1 \end{pmatrix}  \\
QA & =\begin{pmatrix}1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix}1 & 0 \\ 0 & -1 \end{pmatrix} =\begin{pmatrix}1 & -1 \\ 1 & 1 \end{pmatrix} 
\end{align}
$$
#### Remark:
$A$ has eigenvalues ${} 1,\, -1 {}$, and $B$ has eigenvalues ${} 1,\, -1 {}$. This is not a coincidence. Also note that 
$$
\begin{pmatrix} 1 \\ 1 \end{pmatrix} \text{ and } \begin{pmatrix} 1 \\ -1 \end{pmatrix} 
$$
are eigenvectors of $B$. This is also not a coincidence. (spoilers :3)
### Motivation for Similarity
Recall from LAG1: *change of  basis*.
Let $V$ be a vector space with a basis ${} \mathcal{A}=\{ \mathbf{a}_{1},\,\dots,\,\mathbf{a}_{n} \} {}$, and let ${} \mathcal{B}=\{ \mathbf{b}_{1},\,\dots,\,\mathbf{b}_{n}  \} {}$ be another basis for $V$. Let $T:V\to{}V {}$ be a linear operator, and let $A$ be the matrix of $T {}$ with respect to ${} \mathcal{A}$, and $B$ be the matrix of $T$ with respect to $\mathcal{B} {}$.
![[Pasted image 20240118114503.png|400]]
Let ${} Q$ be the *change of basis matrix* from $\mathcal{A}$ to $\mathcal{B}$. Now ${} B=QAQ^{-1} {}$. Therefore, if 2 matrices are similar, then they are the *same* linear operator with respect to different bases. This essentially means that they have the "same properties" (up to a point).
## Characteristic Polynomial
### Definition 1.4: Characteristic Polynomial:
Let ${} A \in M_{n}(\mathbb{F}) {}$. Then the *characteristic polynomial* of $A$ is
$$
p_{A}(x)=\det(A-xI)
$$
#### Example:
$$
A=\begin{pmatrix}1 & 2 \\ 0 & 3 \end{pmatrix} 
$$
Now
$$
\begin{align}
 p_{A}(x)=\det(A-xI) & =  \det  \begin{pmatrix}1-x  &  2 \\ 0 & 3-x \end{pmatrix}  \\
 & =(1-x)(3-x) \\
 & =x^{2}=4x+3
 \end{align}
$$
#### Example:
$$
B=\begin{pmatrix}1 & 2 \\ 3 & 4 \end{pmatrix} 
$$
Now
$$
\begin{align}
 p_{B}(x) = \det(B-xI)  & =\det \begin{pmatrix}1-x & 2 \\ 3 & 4-x \end{pmatrix}  \\
 & =(1-x)(4-x)-2\cdot 3 \\
 & =x^{2}-5x+4-6 \\
 & =x^{2}-5x-2 
 \end{align}
$$
### Lemma 1.5: 
Let ${} A \in M_{n}(\mathbb{F}) {}$, and ${} p_{A}(x)$ be it's characteristic polynomial. Now 
$$
\sigma(A)=\{ \lambda \in \mathbb{F} \mid p_{A}(\lambda)= 0\}
$$
that is, the eigenvalues of $A$ are exactly the roots of the characteristic polynomial.
#### Example:
$$
A=\begin{pmatrix}1 & 2 \\ 0 & 3 \end{pmatrix} \qquad \qquad p_{A}(x)=(1-x)(3-x)
$$
The lemma says that ${} \sigma(A)=\{ 1,\, 3 \} {}$. To check, we find 
$$
\begin{align}
 \mathbf{v}_{1}  & :A\mathbf{v}_{1}=\mathbf{v}_{1}  \\
 \mathbf{v}_{2} & :  A\mathbf{v}_{2}=\mathbf{v}_{2}
 \end{align}
$$
1. ${} A\mathbf{v}_{1}=\mathbf{v}_{1} {}$. Let ${} \mathbf{v}_{1}=\begin{pmatrix} x \\ y \end{pmatrix}  {}$. Lets solve
$$
\begin{align}
\begin{pmatrix}1 & 2 \\ 0 & 3 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} &  =\begin{pmatrix} x \\ y \end{pmatrix}  \\
		\begin{pmatrix} x+2y \\ 3y \end{pmatrix}  & =\begin{pmatrix} x \\ y \end{pmatrix}  \\
\Rightarrow \quad y=0, & \,\, x=x
\end{align}
$$
If we pick ${} x=1 {}$, then ${} \mathbf{v}_{1}=\begin{pmatrix} 1 \\ 0 \end{pmatrix}  {}$
2. ${} A\mathbf{v}_{2}=3\mathbf{v}_{2} {}$. Let ${} \mathbf{v}_{2}=\begin{pmatrix} x \\ y \end{pmatrix}  {}$. Lets solve
$$
\begin{align}
\begin{pmatrix}1 & 2 \\ 0 & 3 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}  & =3 \begin{pmatrix} x \\ y \end{pmatrix}  \\
\begin{pmatrix} x+2y \\ 3y \end{pmatrix}  & =\begin{pmatrix} 3x \\ 3y \end{pmatrix}  \\
\Rightarrow \quad x=y,\,  & y=y
\end{align}
$$
Let ${} y=1 {}$, so ${} \mathbf{v}_{2}=\begin{pmatrix} 1 \\ 1 \end{pmatrix}  {}$. Therefore, both $1$ and $3$ are eigenvalues.
#### Proof of Lemma:
We want to show that ${} \lambda \in \sigma(A) \iff p_{A}(\lambda)=0 {}$.

Let ${} \lambda \in \sigma(A) {}$. Therefore, there exists some $\mathbf{v}\neq 0 {}$ with ${} A\mathbf{v}=\lambda \mathbf{v} {}$. Therefore, ${} \mathbf{v} \in \ker (A-\lambda I) {}$, so the kernel of $A-\lambda I {}$ is *non-trivial*, since $\mathbf{v}$ is non-zero, so ${} A-\lambda I {}$ is not invertible. Therefore, ${} \lambda \in \sigma(A) {}$ iff ${} \det(A-\lambda I)=0=p_{A}(\lambda) {}$. 
