---
tags:
  - prob_stats1
  - chapter
date: 2024-01-16
---
#
	}[[Directory]], [[Probability and Statistics 1|Subject Directory]]
[[Subjects/Probability and Statistics 1/1. Intro|Last]] ;; [[ |Next]]
# Interpretations of Probability
### Classical
Works with a set of equally likely outcomes. Probabilities are calculated or determined by enumerating all outcomes and successes, and dividing the 2 numbers 

It's good for cards/dice, etc, i.e. *discrete systems*
It's not good for figuring out weather it's going to rain tomorrow
### Frequentist
Experiments are repeatable. For example, lets flip a drawing pin, and see if it's point points up, or down. Frequentists suppose that there is a number that describes the probability of it pointing down exists, and can be calculated using relative frequency, where you do many experiments and take the average. It's great for science thanks to it's nature, but it kind of bad for doing lots of real world things.
### Bayesian
What is the probability that it rained in London on 16-01-2023 (exactly a year ago). Now what if we say that *in the morning* it had clear blue skies? The Bayesians say that the probability should change, and that probability is based on the subjective amount of information an observer has. If the information changes, then the probability should change
# Finally Some Maths
## Basis of Probability 
### Sample Space
The sample space is the set of all possible outcomes, usually called ${} \Omega$. For example, the sample space of a coin flip is ${} \Omega=\{ H, T \} {}$, or the sample space of rolling 2 dice is ${} \Omega=\{ (a,\, b) \mid a,\, b \in \{ 1,\, 2,\,\dots,\,6 \} \} {}$. 

The sample space of how long someone hold their breath is
$$
\Omega=\mathbb{R}^{+}
$$
### Events
A subset of $\Omega$ is an *event*. An event is a subset ${} A \subseteq \Omega {}$ where it's elements are all outcomes that cause the event to happen. The great thing about events is we get to use set theory.
### Set theory
If we have a sample space $\Omega {}$ and events ${} A,\, B \subseteq \Omega {}$. Now 
$$
\begin{align}
A \cup B \qquad & \text{ means atleast one of } A \text{ or }B \text{ occours} \\
A \cap B \qquad & \text{ means both } A \text{ and } B \text{ occour} \\
A \setminus B \qquad  &  \text{ means } A \text{ occours but } B \text{ doesnt} \\
A^{\mathrm{c}}=\Omega \setminus A \qquad  & \text{ means }A \text{ does not occour} 
\end{align}
$$
If ${} A \cap B=\varnothing {}$, then $A$ and $B {}$ are mutually exclusive
## Set Theory Stuff
### Theorem 1.1: Distributivity Laws
- ${} A \cap(B \cup C)=(A \cap B ) \cup(A \cap C) {}$
- ${} A \cup(B \cap C)=(A \cup B ) \cap(A \cup C) {}$
#### Proof:
The proof of the first is identical to the proof of the second, so we will only prove the first.
Let ${} x \in A \cap(B\cup C)$. Then ${} x \in A {}$ and ${} x \in B {}$ or ${} x \in C {}$. Therefore, ${} x \in A {}$ and ${} x \in B {}$ or ${} x \in A {}$ and ${} x \in C {}$. Therefore, ${} x \in A \cap B {}$ or ${} x \in A \cap C {}$, so ${} x \in (A \cap B) \cup (A \cap C) {}$.

Conversely, let ${} x \in (A \cap B) \cup (A \cap C) {}$. Then ${} x \in A\cap B {}$, or ${} x \in A \cap C {}$, so ${} x \in A {}$ and ${} x \in B {}$ or ${} x \in A {}$ and ${} x \in C {}$. Therefore, ${} x \in A {}$ and $x \in B {}$ or ${} x \in C {}$, and ${} x \in A {}$ and ${} x \in B \cup C {}$, so ${} x \in A \cap(B \cup C) {}$.
### Theorem 1.2: De Morgan's Laws
- ${} (A \cup B)^{\mathrm{c}}=A^{\mathrm{c}} \cap B^{\mathrm{c}} {}$
- ${} (A \cap B)^{\mathrm{c}}=A^{\mathrm{c}}\cup B^{\mathrm{c}} {}$.
#### Proof:
Exercise Sheet

# Probabilities
## Axiomatic Approach
We want to assign a probability to all possible outcomes, i.e. to every event in ${} \Omega {}$. 
### Definition 2.1: Probability Axioms:
Given a sample space $\Omega$ and a collection of events $\mathcal{E}$, there is a *probability function*, $\mathbb{P}:\mathcal{E}\to{}\mathbb{R} {}$ which defines a *probability measure*. $\mathbb{P}$ obeys the following axioms:
1. For all ${} A \in \mathcal{E} {}$, $\mathbb{P}(A)\geq 0$
2. ${} \mathbb{P}(\Omega)=1 {}$
3. If a *countable* collection of events ${} \{ A_{i} \}_{i \in I} {}$, $I {}$ is countable, with ${} i,\, j \in I,\, i\neq j {}$ implying that ${} A_{i} \cap A_{j}=\varnothing {}$, (that is, non-equal elements are disjoint), then
$$
\mathbb{P}\left( \bigcup_{i\in I} A_{i} \right)=\sum_{i \in I} \mathbb{P}(A_{i})
$$
### Comments on events:
#todo 

