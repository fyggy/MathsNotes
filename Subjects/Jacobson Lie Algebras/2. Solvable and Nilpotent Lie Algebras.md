---
tags:
  - jacobson_lie_algebra
  - exercises
date: 2024-01-22
---
[[Directory]], [[Jacobson Lie Algebras|Subject Directory]]
[[Lie algebras - Nathan Jacobson.pdf#page=66|Exercise Sheet]]
1. 
Let ${} \mathfrak{L} {}$ be a lie algebra over a algebraically closed field ${} \Phi {}$ of characteristic 0. Let ${} \mathfrak{B}\subset \mathfrak{L} {}$ be a solvable proper subalgebra of dimension $m {}$. Consider ${} \mathfrak{L} / \mathfrak{B} {}$. Then $\ad \mathfrak{B} {}$ induces a system of linear transformations, ${} \bar{\ad \mathfrak{B}} {}$ of ${} \mathfrak{L} /\mathfrak{B}=\bar{\mathfrak{L}} {}$. Now $\ad \mathfrak{B}$ is solvable, so ${} \bar{\ad \mathfrak{B}} {}$ is solvable. Therefore, there exists some vector ${} x \in \bar{\mathfrak{L}} {}$ with ${} \conj{\ad B}  \in \bar{\ad \mathfrak{B}},\, (\bar{\ad B})x=\alpha x {}$, for all ${} B \in \mathfrak{B} {}$, that is, $x$ is an eigenvector for all of ${} \bar{\ad \mathfrak{B}} {}$. Now ${} x \Phi=\span\{x\} {}$ is irreducible under ${} \bar{\ad \mathfrak{B}} {}$. Therefore, there exists some ${} \mathfrak{M} \subseteq \mathfrak{L} {}$ with ${} \mathfrak{B} \subseteq  \mathfrak{M} {}$ and ${} \mathfrak{M} / \mathfrak{B} \cong  x\Phi {}$. Since ${} \dim x\Phi=1 {}$, then ${} \dim \mathfrak{M}=m+1 {}$, as required.
2. skip
3. 
Let ${} \mathfrak{L} {}$ be a solvable subalgebra of ${} \Phi^{n}_{L} {}$. Then there exists a basis of $\mathfrak{L}$ such that every element of $\mathfrak{L}$ is in triangular form. Therefore, there are at most ${} n(n+1)/2 {}$ independent variables, so ${} \dim \mathfrak{L} \leq n(n+1) /2 {}$. 

Now consider the subalgebra $\mathfrak{R} {}$ consisting of all upper triangular matrices. This is solvable. Now let ${} Q \in \Phi^{n} {}$ be the invertible matrix such that ${} Q^{-1}\mathfrak{L}Q {}$ is in triangular form. Now this is clearly a subalgebra of ${} \mathfrak{R}$, so ${} \mathfrak{L} \subseteq Q^{-1}\mathfrak{R} {}$, and so $\mathfrak{L} {}$ is contained in a solvable subalgebra of dimension ${} n(n+1) /2 {}$.

Let $\mathfrak{L}_{1} {}$ and $\mathfrak{L}_{2}$ be solvable subalgebras of dimension ${} n(n+1) / 2 {}$. Then there exist 2 regular matrices ${} P,\, Q {}$ such that ${} P^{-1}\mathfrak{L}_{1} P=\mathfrak{R}=Q^{-1}\mathfrak{L}_{2}Q {}$. Now we have 
$$
PQ^{-1}\mathfrak{L}_{2} (PQ^{-1})^{-1}=\mathfrak{L}_{1}
$$
Setting ${} A=PQ^{-1} {}$, we get our solution.
4. 
Let ${} \Phi {}$ be algebraically closed, and let ${} \mathfrak{L}$ be a Lie algebra over $\Phi {}$ which is *not* nilpotent. Now note that every element of $\ad \mathfrak{L}$ has an eigenvector. Since $\ad \mathfrak{L}$ is not nilpotent, then there exists some element ${} f \in \mathfrak{L} {}$ which is not nilpotent. Therefore, ${} \ad f {}$ has a nonzero eigenvalue $\alpha {}$ associated with an eigenvector ${} e {}$. Note that $e {}$ and $f {}$ are linearly independent, as otherwise ${} e=\beta f {}$ ${} \ad (f)(\beta f)=0 {}$ has a eigenvalue of ${} 0$. Now
$$
[e,\, f]=\alpha e
$$
and the subalgebra spanned by ${} e,\, f {}$ is 2 dimensional and non-abelian.
5. 
Let $\Phi$ be an algebraically closed field. We skip the first part. Let $\mathfrak{A}$ be a non-associative algebra. Let $A$ be an automorphism of $\mathfrak{A}$, and let ${} S {}$ be a linear transformation with the restriction of $S$ to $\mathfrak{A}_{\alpha}$ being ${} S_{|\mathfrak{A}_{\alpha}}=\alpha I {}$. 

Now let ${} x \in \mathfrak{A} {}$. Since ${} \mathfrak{A}=\bigoplus_{\alpha}\mathfrak{A}_{\alpha} {}$ relative to $A {}$, then ${} x=\sum_{\alpha} x_{\alpha} {}$ uniquely. Now 
$$
\begin{align}
 ASx & =AS\left( \sum_{\alpha}x_{\alpha} \right)   \\
 & =A \sum_{\alpha} \alpha x_{\alpha} \\
 & =\sum_{\alpha} \alpha Ax_{\alpha} \\
 & = \sum_{\alpha}SAx_{\alpha}  &  & \text{since } \mathfrak{A}_{\alpha} \text{ is stable over } A\\
 & =SA \left( \sum_{\alpha} x_{\alpha} \right) \\
 & = SAx
 \end{align}
$$
So $A$ and $S$ commute. Now let ${} x \in \ker S {}$. Now we have
$$
\begin{align}
Sx & =0 \\
S\left( \sum_{\alpha}x_{\alpha} \right) & =0 \\
\sum \alpha x_{\alpha} & =0 \\
\Rightarrow \quad\forall \alpha: \alpha x_{\alpha} & =0 
\end{align}
$$
Now if ${} \alpha=0 {}$, then since $A$ is an automorphism, then ${} \mathfrak{A}_{\alpha}=0 {}$. Therefore, all ${} x_{\alpha}=0 {}$, so ${} x=0 {}$. Therefore, $S$ is a bijection. Now let ${} x,\, y \in \mathfrak{A} {}$. Note that if ${} xy=\sum_{\gamma}x_{\gamma} {}$, then
$$
\begin{align}
S(x) S(y) & =\sum_{\alpha} \alpha x_{\alpha} \cdot  \sum_{\beta} \beta y_{\beta} \\
	 & =\sum_{\alpha,\, \beta}\alpha\beta x_{\alpha} y_{\beta}
\end{align}
$$
If $\alpha \beta$ is a characteristic root, then ${} x_{\alpha} y_{\beta} \in \mathfrak{A}_{\alpha\beta} {}$. Otherwise, ${} x_{\alpha} y_{\beta}=0 {}$. If $\alpha\beta {}$ is a characteristic root, let ${} \gamma=\alpha\beta {}$, and let ${} z_{\gamma}=x_{\alpha}y_{\beta} {}$ Now
$$
\begin{align}
S(x)S(y) & =\sum_{\gamma} \gamma z_{\gamma} \\
 & =S\left( \sum_{\gamma} z_{\gamma} \right)
\end{align}
$$
Now note that
$$
\begin{align}
 xy  & = \sum_{\alpha} x_{\alpha} \cdot \sum_{\beta} y_{\beta} \\
 & =\sum_{\gamma} z_{\gamma}
 \end{align}
$$
Therefore, ${} S(x)S(y)=S(xy) {}$, so $S$ is an automorphism of $\mathfrak{A}$. 

Finally, let ${} U=S^{-1}A {}$. Clearly, $U {}$ is an automorphism. Since $\Phi {}$ is algebraically closed, then there exists an eigenvector ${} e {}$ of ${} A {}$ with eigenvalue $\alpha {}$. Now 

Let $e {}$ be an eigenvector of $U-I {}$ with eigenvalue $\alpha$. Now
$$
\begin{align}
 (U-I)e & =\alpha e   \\
S^{-1}Ae-e & =\alpha e \\
S^{-1}Ae & =(\alpha+1)e \\
 \end{align}
$$
Therefore, $e$ is an eigenvector of $U$. 

Let $e {}$ be an eigenvector of $U {}$ with eigenvalue ${} \beta {}$. We see that if ${} e=\sum_{\alpha} e_{\alpha} {}$ and ${} f_{\alpha}=Ae_{\alpha} {}$
$$
S^{-1}Ae=S^{-1}\sum_{\alpha} f_{\alpha} =\sum_{\alpha} \frac{1}{\alpha} f_{\alpha}=\sum_{\alpha} \beta e_{\alpha}
$$
So now for all eigenvalues $\alpha {}$ of ${} A {}$, 
$$
\frac{1}{\alpha}f_{\alpha}=\beta e_{\alpha}
$$
so therefore, all ${} e_{\alpha} {}$ are eigenvectors of ${} A {}$ with eigenvalue $\alpha\beta {}$. Therefore, ${} \beta=1 {}$, since if ${} e_{\alpha} \in \mathfrak{M}_{\alpha} {}$, then it has eigenvalue $\alpha$. Therefore, all eigenvectors of $U$ have eigenvalue $1$, so all eigenvalues of ${} Z=U-I {}$ have eigenvalue $0$, therefore, $Z {}$ is nilpotent.
6. 
Let ${} X=\ad x \in \ad \mathfrak{L}_{\alpha} {}$ and ${} Y=\ad y \in  \ad  \mathfrak{L}_{\beta} {}$. Now note that ${} [X,\, Y]=\ad x \ad y - \ad y \ad x {}$ so we have, for some ${} z=\sum_{\alpha}z_{\alpha} \in \mathfrak{L} {}$,
$$
	\begin{align}
 [X,\, Y](z) & =[x,\, [y,\, z]]-[y,\, [x,\, z]]   \\
 & = -[z,\, [x,\, y]] \\
 & =[[x,\, y],\, z]
 \end{align}
$$
Now we see that if $\alpha\beta {}$ is a eigenvalue of ${} A {}$, then ${} [x,\, y] \in \mathfrak{L}_{\alpha \beta} {}$. Otherwise, ${} [x,\, y]=0 \in \mathfrak{L}_{\alpha \beta} {}$. Therefore, there exists some ${} K=\ad k \in \mathfrak{W} {}$ with ${} K(z)=[X,\, Y](z) {}$, so ${} [X,\, Y]=K {}$, so $\mathfrak{W}$ is weakly closed.
7. 
Let $A$ be an automorphism over $\mathfrak{L}$ of prime order, that is, there exists some prime $p$ with ${} A^{p}=I {}$. Suppose that if ${} Ax=x {}$, then ${} x=0 {}$. We see that therefore, all eigenvalues of $A {}$ have order $p {}$ as well, as if $x {}$ is an eigenvector of ${} A {}$ with eigenvalue $\alpha {}$, then ${} x=A^{p}x=\alpha^{p}x. {}$ 

First, note that if ${} \char \Phi=p {}$, we have that, given a eigenvalue $\alpha {}$ of ${} A {}$, then since ${} p\mid\binom{p}{i}  {}$ if ${} i\neq 0, p {}$
$$
\begin{align}
 \mathfrak{L}_{\alpha} & =\ker (A-\alpha I)^{p}   \\
 & =\ker \left( \sum_{i=0}^{p} \binom{p}{i} A^{p-i}(-\alpha)^{i} \right) \\
 & =\ker ((-\alpha)^{p}I+A^{p}) \\
 & =\ker ((-1)^{p} I+I)
 \end{align}
$$
Now if $p$ is odd, then we have that this is the kernel of the zero map, that is, $\mathfrak{L}$. Otherwise, if $p$ is even, then 
$$
\mathfrak{L}_{\alpha}=\ker (2I)=\ker 0=\mathfrak{L}
$$
Therefore, ${} \mathfrak{L}=\mathfrak{L}_{\alpha} {}$. Now this implies that there is exactly 1 eigenvector, $\alpha$. Therefore, $\alpha^{2}$ is not an eigenvector, as if ${} p=2 {}$, then $1$ is not an eigenvector by hypothesis, or otherwise, then $\alpha^{2}\neq\alpha$, as that would imply that ${} \alpha=1,\, 0 {}$, which is also contrary to hypothesis. Therefore, ${} [\mathfrak{L}_{\alpha} ,\, \mathfrak{L}_{\alpha}]=0 {}$, so $\mathfrak{L}$ is abelian, and therefore nilpotent. 

Now consider ${} \char \Phi=q\neq p {}$. By exercise $5$ above, we have that ${} A=S(I+Z) {}$. Now note that $A^{q}\neq I {}$ and ${} S^{q}\neq I {}$, but ${} S^{p}=I {}$. Therefore, ${} I=A^{p}=S^{p}(I+Z)^{p}=(I+Z)^{p} {}$. Now we may pick some ${} k {}$ large enough that ${} Z^{q^{k}}=0 {}$, as $Z {}$ is nilpotent. Now
$$
\begin{align}
 A^{q^{k}} & =S^{q^{k}}(I+Z)^{q^{k}}   \\
 & =S^{q^{k}}(I+Z^{q^{k}}) \\
 & =S^{q^{k}}
 \end{align}
$$
Now since ${} \gcd(p,\, q^{k})=1 {}$, then we have integers ${} a,\, b {}$ such that ${} 1+ap=bq^{k} {}$, that is,
$$
S=S^{1+ap}=( S^{q^{k}} )^{b}=(A^{q^{k}})^{b}=A^{1+ap}=A
$$
Alternatively, consider ${} \char \Phi=0 {}$. Again by exercise $5$ above, we have ${} A=S(I+Z) {}$. Now we see that, if the nil weight of $Z {}$ is ${} k {}$ then if ${} k_{1}\geq k {}$
$$
(I+Z)^{k-1} = (I+Z)^{k_{1}}
$$
Now ${} (I+\lambda)^{k_{1}}-I {}$ is a polynomial of degree ${} k-1 {}$, and therefore, since the minimal polynomial of ${} Z$ is ${} \lambda^{k}$, then ${} (I+Z)^{k_{1}}-I\neq 0 {}$, so ${} (I+Z)^{k_{1}}\neq I {}$, so $I+Z {}$ has infinite order, unless, of course, ${} k=1 {}$ and ${} Z=0 {}$. Therefore since
$$
1=A^{p}=S^{p}(I+Z)^{p}=(I+Z)^{p}
$$
Then ${} Z=0 {}$, and $A=S {}$. 

Therefore, in both cases, ${} A=S {}$. Therefore, every generalised eigenspace is an eigenspace, and their elements are all eigenvectors. Now let ${} X=\ad x_{\alpha} \in \mathfrak{L}_{\alpha} \subseteq \mathfrak{W} {}$, and let ${} y \in \mathfrak{L} {}$ be an eigenvector of $X$ with eigenvalue $\beta$. We see that ${} y=\sum_{\gamma}y_{\gamma} {}$. Now 
$$
\begin{align}
 A\beta y & =A[x_{\alpha},\, y]  \\
  & =\left[ Ax_{\alpha},\, \sum_{\gamma} Ay_{{\gamma}} \right] \\
 & =\sum_{\gamma} [\alpha x_{\alpha},\, \gamma y_{\gamma}] \\
 & =\alpha\sum_{\gamma} \gamma [x_{\alpha},\, y_{\gamma}]
 \end{align}
$$