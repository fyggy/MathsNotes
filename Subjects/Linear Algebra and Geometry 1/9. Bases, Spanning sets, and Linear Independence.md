---
tags:
  - linear_algebra1
  - chapter
date: 2023-10-23
---
[[Directory]], [[Linear Algebra and Geometry 1|Subject Directory]]
# Bases
## Introduction
### Definition 1.1
A collection of vectors ${} \mathbf{v}_{1},\, \mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n}$ in a vector space $V$ is a *basis* for $V {}$ if every ${} \mathbf{v}\in V {}$ can be written as a unique linear combination of $\mathbf{v}_{1},\,\dots,\,\mathbf{v}_{n} {}$, that is, there exists unique ${} \alpha_{1} ,\, \alpha_{2},\,\dots,\,\alpha_{n}\in \mathbb{F} {}$ such that
$$
\mathbf{v}=\alpha_{1}\mathbf{v}_{1}+\alpha_{2}\mathbf{v}_{2}+\dots+\alpha_{n}\mathbf{v}_{n}=\sum_{k=1}^{n} \alpha_{k}\mathbf{v}_{k}
$$
#### Examples
1. 
${} V=\mathbb{F}^{n} {}$. Consider:
$$
\mathbf{e}_{1}=\begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix} ,\, \mathbf{e}_{2}=\begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix} ,\,\dots,\,\mathbf{e}_{n}=\begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix} 
$$
This is a basis of ${} \mathbb{F}^{n}$, called the standard basis of ${} \mathbb{F}^{n} {}$
2. 
${} V=\mathbb{P}_{n} {}$. Consider the vectors
$$
\mathbf{e}_{0}(t)=1,\, \mathbf{e}_{1}(t)=t,\, \mathbf{e}_{2}(t)=t^{2},\,\dots,\,\mathbf{e}_{n}(t)=t^{n}
$$
This is a basis of $\mathbb{P}_{n}$, as given a polynomial
$$
P(t)=a_{0}+a_{1}t+\dots+a_{n}t^{n}
$$
Can be uniquely represented as
$$
P=a_{0}\mathbf{e}_{0}+a_{1}\mathbf{e}_{1}+\dots+a_{n}\mathbf{e}_{n}
$$
Therefore, $\mathbf{e}_{0},\,\dots,\,\mathbf{e}_{n}$ is a basis of ${} \mathbb{P}_{n} {}$

### Fact
This is beyond the scope of this course
*Every* Vector space has a basis. In fact, every vector space has many bases.

#### Example
The following are alll basis of $\mathbb{R}^{2} {}$:
$$
\left\{  \begin{pmatrix} 1 \\ 0 \end{pmatrix} ,\, \begin{pmatrix} 0 \\ 1 \end{pmatrix}   \right\},\, \left\{  \begin{pmatrix} 1 \\ 1 \end{pmatrix} ,\, \begin{pmatrix} 0 \\ 1 \end{pmatrix}   \right\},\, \left\{  \begin{pmatrix} -1 \\ 0 \end{pmatrix}   \begin{pmatrix} 0 \\ -1 \\  \end{pmatrix} \right\},\,\dots\,
$$

### Definition 1.2
Let ${} V {}$ be a vector space with a basis ${} \mathcal{E}=\{ \mathbf{e}_{1},\, \mathbf{e}_{2},\,\dots,\,\mathbf{e}_{n} \} {}$. The coordinate vector of $\mathbf{v}=\alpha_{1}\mathbf{e}_{1}+\alpha_{2}\mathbf{v}_{2}+\dots+\alpha_{n}\mathbf{v}_{n} {}$ is the column vector
$$
[\mathbf{v}]_{\mathcal{E}}=\begin{pmatrix} \alpha_{1}ma \\ \alpha_{2} \\ \vdots \\ \alpha_{n} \end{pmatrix} \in \mathbb{F}^{n}
$$
We have a one-t-one correspondence (bijection) between $V$ and ${} \mathbb{F}^{n}$
$$
{} \mathbf{v}\longleftrightarrow [\mathbf{v}]_{\mathcal{E}} {}
$$
If ${} \mathbf{v}=\sum_{k=1}^{n} \alpha_{k}\mathbf{e}_{k} {}$ and ${} \mathbf{w}=\sum_{k=1}^{n} \beta_{k}\mathbf{e}_{k} {}$, and $\gamma \in \mathbb{F} {}$, then
$$
\mathbf{v}+\mathbf{w}=(\alpha_{1}+\beta_{1})\mathbf{e}_{1}+(\alpha_{2}+\beta_{2})\mathbf{e}_{2}+\dots+(\alpha_{n}+\beta_{n})\mathbf{e}_{n}
$$
So
$$
[\mathbf{v}+\mathbf{w}]_{\mathcal{E}}=\begin{pmatrix} \alpha_{1}+\beta_{1} \\ \alpha_{2}+\beta_{2} \\ \vdots \\\alpha_{n}+\beta_{n}   \end{pmatrix} =[\mathbf{v}]_{\mathcal{E}}+[\mathbf{w}]_{\mathcal{E}}
$$
and
$$
\gamma \mathbf{v}=\gamma\alpha_{1}\mathbf{e}_{1}+\gamma\alpha_{2}\mathbf{e}_{2}+\dots+\gamma\alpha_{n}\mathbf{e}_{n}
$$
so
$$
[\gamma \mathbf{v}]_{\mathcal{E}}=\begin{pmatrix} \gamma\alpha_{1} \\ \gamma\alpha_{2} \\ \vdots \\ \gamma\alpha_{n} \end{pmatrix} =\gamma[\mathbf{v}]_{\mathcal{E}}
$$
Therefore, we have that ${} [{}\cdot{} ]_{\mathcal{E}} {}$ is a bijection from $[{}\cdot {}]:V\to{}\mathbb{F}^{n} {}$.

## Spanning and Linearly Independent Sets
${} \mathbf{e}_{1},\, \mathbf{e}_{2},\,\dots,\,\mathbf{e}_{n} {}$ is a basis of $V {}$ if
1. for all ${} \mathbf{v} \in V {}$, there exists (not necessarily unique) representation ${} \mathbf{v}=\alpha_{1}\mathbf{e}_{1}+\alpha_{2}\mathbf{e}_{2}+\dots+\alpha_{n}\mathbf{e}_{n} {}$
2. Any representation of ${} \mathbf{v} {}$ is unique.

### Definition 1.3: Spanning Set
${} \mathbf{v}_{1},\, \mathbf{v}_{2},\, \dots,\, \mathbf{v}_{n} {}$ span ${} V$ (or are spanning, or a generating set) if every ${} \mathbf{v}\in V {}$can be written as a linear combination
$$
\mathbf{v}=\alpha_{1}\mathbf{v}_{1}+\alpha_{2}\mathbf{v}_{2}+\dots+\alpha_{n\mathbf{v}_{ }}
$$
Note that ${} \mathbf{v}_{1},\, \mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n} {}$ span $V$ iff $\span\{\mathbf{v}_{1},\, \mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n}\}=V {}$
### Definition 1.4: Linear Dependence and Independence
A collection of vectors ${} \mathbf{v}_{1},\, \mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n}\in V {}$ are linearly dependant (or just dependant) if there are scalars ${} \alpha_{1},\, \alpha_{2},\,\dots,\,\alpha_{n}\in \mathbb{F} {}$ which are not all zero such that
$$
\alpha_{1}\mathbf{v}_{1}+\alpha_{2}\mathbf{v}_{2}+\dots+\alpha_{n}\mathbf{v}_{n}=\mathbf{0}
$$
Vectors are *linearly independent* if they are not linearly dependant
####  Note:
To be a basis, a list must be linearly independent

### Proposition 1.5: Removal Theorem
The vectors ${} \mathbf{v}_{1},\, \mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n}\in V {}$ are linearly dependant if and only if one of the ${} \mathbf{v}_{k}  {}$ can be written as a combination of the others. 
#### Proof:
Suppose ${} \mathbf{v}_{1},\,\dots,\,\mathbf{v}_{n} {}$ are linearly dependent. Then there are ${} \alpha_{1},\, \alpha_{2},\,\dots,\,\alpha_{n}\in \mathbb{F}$ not all zero such that ${} \alpha_{1}\mathbf{v}_{1}+\alpha_{2}\mathbf{v}_{2}+\dots+\alpha_{n}\mathbf{v}_{n}=\mathbf{0} {}$. WLOG, we assume that ${} \alpha_{1}\neq 0 {}$.

Then
$$
\alpha_{1}\mathbf{v}_{1}=-\alpha_{2}\mathbf{v}_{2}-\alpha_{3}\mathbf{v}_{3}-\dots-\alpha_{n}\mathbf{v}_{n}
$$
so
$$
	\mathbf{v}_{1}=\left( -\frac{\alpha_{2}}{\alpha_{1}} \right)\mathbf{v}_{2}+\dots+\left( -\frac{\alpha_{n}}{\alpha_{1}} \right)\mathbf{v}_{n}
$$
So ${} \mathbf{v}_{1}$ is a linear combination of ${} \mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n} {}$. See the lecture notes for the converse
#### Key point: 
if ${} \mathbf{v}_{1},\, \mathbf{v}_{2},\,\dots,\,\, \mathbf{v}_{n} {}$ are linearly independent, we can fond some ${} \mathbf{v}_{k}$ which can be removed without changing the span.