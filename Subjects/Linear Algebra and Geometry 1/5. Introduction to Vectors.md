---
tags:
  - chapter
  - linear_algebra1
date: 2023-10-09
---
[[Directory]], [[Linear Algebra and Geometry 1|Subject Directory]]
# Vectors
## Vectors in ${} \mathbb{R}^{n}$ and $\mathbb{C}^{n}$
### Vectors in 2 dimensions
Given $v_{1}, v_{2} \in \mathbb{R}$, we can combine them to form a vector:
$\mathbf{v}=\begin{pmatrix}v_{1}\\v_{2}\end{pmatrix}$. This is a column vector. However, we will sometimes write a vector as $\mathbf{v}=(v_{1},\,v_{2})$. These are the same thing. 

If we take the set of all pairs of this form, this is denoted $\mathbb{R}^{2}$. We can visualise these as points in the plane:
![[Pasted image 20231009120945.png]]
Similarly, given $v_{1},\,v_{2},\,v_{3} \in \mathbb{R}$, we can form a column vector of length $3$:
$$
\mathbf{v}=\begin{pmatrix}
v_{1} \\
v_{2} \\
v_{3}
\end{pmatrix}
$$
The set of all such triples is denoted $\mathbb{R}^{3}$. 
![[Pasted image 20231009121430.png]]

### Definition 1.1#
Let $n \in \mathbb{N}$. The space $\mathbb{R}^{n}$ consists of columns of length $n$:
$$
\mathbf{v}=\begin{pmatrix}
v_{1} \\
v_{2} \\
\vdots \\
v_{n}
\end{pmatrix}\text{ where } v_{1},\, v_{2},\, \dots,\, v_{n}\in\mathbb{R}
$$
$v_{1},\,v_{2},\,\dots,\,v_{n}$ are called entries, components or coordinates of $\mathbf{v}$

Similarly, the space $\mathbb{C}^{n}$ consists of vectors of length n with entries in $\mathbb{C}$

#### Notation:
We will write $\mathbb{F}$ to mean either $\mathbb{R}$ or $\mathbb{C}$ (when it doesn't matter). Really $\mathbb{F}$ can be any field, but in this course we don't mention that, and $\mathbb{F}^{n}$ to be $\mathbb{R}^{n}$ or $\mathbb{C}^{n}$

### Definition 1.2: Vector addition and Scalar Multiplication
#### Addition:
Given 2 vectors in $\mathbb{F}^{n}$, we can add them as so:
$$
\begin{pmatrix}
v_{1}\\v_{2}\\\vdots\\v_{n}
\end{pmatrix}
+
\begin{pmatrix}
w_{1}\\w_{2}\\\vdots\\w_{n}
\end{pmatrix}
=
\begin{pmatrix}
v_{1}+w_{1}\\v_{2}+w_{2}\\\vdots\\v_{n}+w_{n}
\end{pmatrix}
$$
This is called term by term addition.
#### Scalar Multiplication:
For $\alpha \in\mathbb{F}$
$$
\alpha \begin{pmatrix}
v_{1} \\
v_{2} \\
\vdots \\
v_{n}
\end{pmatrix}
=
\begin{pmatrix}
\alpha v_{1} \\
\alpha v_{2} \\
\vdots \\
\alpha v_{n}
\end{pmatrix}
$$
This is called scalar multiplication, and $\alpha$ is called a scalar

#### Notation: 
Write $-\mathbf{v}=(-1)\mathbf{v}$, and we write 
$$
\mathbf{0} \text{ for the zero vector: } \mathbf{0}=\begin{pmatrix}
0 \\
0 \\
\vdots \\
0
\end{pmatrix}
$$

### Definition 1.3
Let $\mathbf{v}_{1}, \mathbf{v}_{2}, \mathbf{v}_{3},\,\dots,\,\mathbf{v}_{n}\in\mathbb{F}^{n}$. Then a linear combination of $\mathbf{v}_{1},\,\dots,\,\mathbf{v}_{n}$ is an expression of the form 
$$
\alpha_{1}\mathbf{v}_{1}+\alpha_{2}\mathbf{v}_{2}+\dots+\alpha_{n}\mathbf{v}_{n}=\sum_{k=1}^{n} \alpha_{k}\mathbf{v}_{k}
$$
Where we have $\alpha_{1},\,\alpha_{2},\,\dots,\,\alpha_{n}\in\mathbb{F}$ are scalars

#### Example:
Let 
$$
\mathbf{u}=\begin{pmatrix}
1 \\
5
\end{pmatrix},\, 
\mathbf{v}=\begin{pmatrix}
2 \\
-2
\end{pmatrix},\, 
\mathbf{w}=\begin{pmatrix}
3 \\
-4
\end{pmatrix}
$$
A linear combination of these vectors could be, for example
$$
\frac{1}{3}(\mathbf{u}-5\mathbf{v}+2\mathbf{w})=\frac{1}{3}\left( \begin{pmatrix}
1\\5
\end{pmatrix}-\begin{pmatrix}
10\\-10
\end{pmatrix}+\begin{pmatrix}
6\\-8
\end{pmatrix} \right) =\begin{pmatrix}
-1 \\
\frac{7}{3}
\end{pmatrix}
$$
### Definition 1.4
The linear span (or just span) of $\mathbf{v}_{1},\,\,\mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n}\in\mathbb{F}^{m}$ is the set of all vectors in $\mathbb{F}^{m}$ that can be written as a linear combination of $\mathbf{v}_{1},\,\dots,\,\mathbf{v}_{n}$

#### Notation:
$\span\{\mathbf{v}_{1},\,\mathbf{v}_{2},\,\dots,\,\mathbf{v}_{n}\}=\left\{ \displaystyle \sum_{k=1}^{n}\alpha_{k}\mathbf{v}_{k}\mid \alpha_{1},\,\alpha_{2},\,\dots,\,\alpha_{n} \in \mathbb{F} \right\}$
#### Note:
If we take $\alpha_{1}=\alpha_{2}=\dots=\alpha_{n}=0$, we get $\mathbf{0}$. So $\mathbf{0}\in \span\{v_{1},\,\dots \mathbf{v}_{n}\}$

#### Example:
Is $(3,\,5,\,-8)$ in the span of $(1,\,3,\,0)$ and $(0,\,-2,\,4)$?
Well, its in the span iff there exist $\alpha,\,\beta \in \mathbb{R}$ such that 
$$
\begin{pmatrix} 3 \\ 5 \\ -8 \end{pmatrix} =\alpha \begin{pmatrix} 1 \\ 3 \\ 0 \end{pmatrix} +\beta \begin{pmatrix} 0 \\ -2 \\ 4 \end{pmatrix} 
$$
Equating components, this is equivalent to 
$$
\begin{align}
3 & =\alpha\cdot1+\beta \cdot 0=\alpha  &  & (1)\\
5 & =3\alpha-2\beta  &  & (2)\\
-8 & =\alpha\cdot 0+4\beta=4\beta  &  & (3)
\end{align}
$$
From $(1)$, $\alpha=3$. For $(3)$, $\beta=-2$. Substituting into $(2)$, we get 
$$
3\alpha-2\beta=9+4=13\neq 5
$$
So $(3,\,5,\,-8)$ is not in the span of $(1, 3, 0)$ and $(0, -2, 4)$

#### Examples:
1. Let $\mathbf{v}\in \mathbb{R}^{n}$ be non zero. Now we have $\span\{\mathbf{v}\}=\{ \alpha \mathbf{v}\mid\alpha \in\mathbb{R} \}$
![[Pasted image 20231009130903.png|450]]
# Geometry of $\mathbb{R}^{n}$ and $\mathbb{C}^{n}$
## Distance
### Definition 2.1
the length (or norm) of $\mathbf{v}=(v_{1},\,v_{2},\,\dots,\,\,v_{n})\in \mathbb{F}^{n}$ is
$$
\lVert \mathbf{v} \rVert  =\sqrt{|v_{1}|^{2}+|v_{2}|^{2}+\dots+|v_{n}|^{2}}
$$
We define the distance between $\mathbf{v}$ and $\mathbf{w}$ to be 
$$
\lVert \mathbf{v}-\mathbf{w} \rVert  
$$

### Proposition 2.2: Properties of Length
For $\mathbf{u},\,\mathbf{v}\in\mathbb{F}^{n}$ and any $\alpha \in \mathbb{F}$, we have
1. $\lVert \mathbf{v} \rVert\geq 0$ and $\lVert \mathbf{v} \rVert=0$ if and only if $\mathbf{v}=\mathbf{0}$
2. $\lVert \alpha \mathbf{v} \rVert=|\alpha|\cdot\lVert \mathbf{v} \rVert$
3. $\lVert \mathbf{u} +\mathbf{v}\rVert\leq \lVert \mathbf{u} \rVert+\lVert \mathbf{v} \rVert$ (triangle inequality)

#### Proof:
1. Since $|v_{1}|^{2}\geq 0$, $|v_{2}|^{2}\geq 0, \dots,\,|v_{n}|^{2}\geq 0$, we have
$$
\lVert \mathbf{v} \rVert =\sqrt{|v_{1}|^{2}+\dots+|v_{n}|^{2}}\geq 0
$$
Moreover, $\lVert \mathbf{v} \rVert=0 \iff |v_{1}|^{2}=|v_{2}|^{2}=\dots=|v_{n}|^{2}=0\iff \mathbf{v}=\mathbf{0}$
2. $\lVert \alpha \mathbf{v} \rVert=\sqrt{|\alpha v_{1}|^{2}+\dots+|\alpha v_{n}|^{2}}=\sqrt{|\alpha|^{2}}\cdot \sqrt{|v_{1}|^{2}+\dots+|v_{n}|^{2}}=|\alpha|\cdot \lVert \mathbf{v} \rVert$
3. This is homework

### Definition 2.3
Let $\mathbf{u}=(u_{1},\,u_{2},\,\dots,\,u_{n}),\,\mathbf{v}=(v_{1},\,v_{2},\,\dots,\,v_{n})\in \mathbb{R}^{n}$
The dot product (or scalar product or inner product) of $\mathbf{u}$ and $\mathbf{v}$ is
$$
\mathbf{u}\cdot \mathbf{v}=u_{1}v_{1}+u_{2}v_{2}+\dots+u_{n}v_{n}=\sum_{k=1}^{n} u_{k}v_{k}
$$

Let $\mathbf{z}=(z_{1},\,\dots,\,z_{n}),\,\mathbf{w}=(w_{1},\,\dots,\,w_{n})\in\mathbb{C}^{n}$. The dot product is 
$$
\mathbf{z} \cdot \mathbf{w}=z_{1}\conj{w_{1}}+z_{2}\conj{w_{2}}+\dots+z_{n}\conj{w_{n}}
$$

#### Note:
If $\mathbf{z},\,\mathbf{w}$ have real entries, then these definitions coincide

#### Remark:
$$
\mathbf{v}\cdot \mathbf{v}=|v_{1}|^{2}+|v_{2}|^{2}+\dots+|v_{n}|^{2}=\lVert \mathbf{v} \rVert ^{2}\qquad(\mathbf{v}\in\mathbb{F}^{n})
$$

### Proposition 2.4: Properties of the dot product
For any $\mathbf{u},\,\mathbf{v},\,\mathbf{w}\in\mathbb{R}^{n}$, and any $\alpha \in\mathbb{R}$, we have
1. $\mathbf{v}\cdot \mathbf{v}\geq 0$ and $\mathbf{v}\cdot \mathbf{v}=0 \iff \mathbf{v}=\mathbf{0}$
2. $\mathbf{v}\cdot \mathbf{u}=\mathbf{u}\cdot \mathbf{v}$
3. $\mathbf{u}\cdot(\mathbf{v}+\mathbf{w})=\mathbf{u}\cdot\mathbf{v}+\mathbf{u}\cdot\mathbf{w}$
4. $(\alpha \mathbf{u})\cdot \mathbf{v}=\mathbf{u}\cdot(\alpha \mathbf{v})=\alpha(\mathbf{u}\cdot \mathbf{v})$

#### Note:
Some of these properties hold in $\mathbb{C}^{n}$, except the following:
2. $\mathbf{z}\cdot \mathbf{w}=\conj{\mathbf{w}\cdot \mathbf{z}}$
4. $(\alpha \mathbf{z})\cdot \mathbf{w}=\mathbf{z}\cdot(\conj{\alpha}\mathbf{w})=\alpha(\mathbf{z}\cdot \mathbf{w})$ 

We don't use the inner product in $\mathbb{C}^{n}$ very much, so don't worry about it too much :)

#### Proof:
1. Since $\mathbf{v}\cdot \mathbf{v}=\lVert \mathbf{v} \rVert^{2}$, this follows from Proposition 2.2(.1)
2. $\mathbf{u}\cdot \mathbf{v}=u_{1}v_{1}+\dots+u_{n}v_{n}=v_{1}u_{1}+\dots+v_{n}u_{n}=\mathbf{v}\cdot \mathbf{u}$
3. $$
\begin{align}
\mathbf{u}\cdot(\mathbf{v}+\mathbf{w}) & =u_{1}(v_{1}+w_{1})+\dots+u_{n}(v_{n}+w_{n}) \\
 & =u_{1}v_{1}+\dots+u_{n}v_{n}+u_{1}w_{1}+\dots+u_{n}w_{n} \\
 & =\mathbf{u}\cdot \mathbf{v}+\mathbf{u}\cdot \mathbf{w}
\end{align}
$$
4. $$
\begin{align}
(\alpha \mathbf{u})\cdot \mathbf{v} & =\alpha u_{1}v_{1}+\dots+\alpha u_{n}v_{n} \\
 & =\alpha(\mathbf{u}\cdot \mathbf{v}) \\
 & =\mathbf{u}\cdot(\alpha \mathbf{v})
\end{align}
$$
### Proposition 2.5: Angles in $\mathbb{R}^{2}$
Let $\mathbf{u},\,\mathbf{v}\in\mathbb{R}^{2}$ and let $\theta$ be the angle between $\mathbf{u}$ and $\mathbf{v}$
![[Pasted image 20231009134706.png|450]]
Then 
$$
\mathbf{u}\cdot \mathbf{v}=\lVert u \rVert \lVert v \rVert \cos\theta
$$

#### Proof:
From the cosine rule $\lVert \mathbf{u}-\mathbf{v} \rVert^{2}=\lVert \mathbf{u} \rVert^{2}+\lVert \mathbf{v} \rVert^{2}-2\lVert \mathbf{u} \rVert \lVert \mathbf{v} \rVert\cos\theta$

However, 
$$
\begin{align}
\lVert \mathbf{u}-\mathbf{v} \rVert ^{2} & =(\mathbf{u}-\mathbf{v})\cdot(\mathbf{u}-\mathbf{v}) \\
 & =\mathbf{u}\cdot \mathbf{u}+\mathbf{v}\cdot \mathbf{v}-\mathbf{v}\cdot \mathbf{u}-\mathbf{u}\cdot \mathbf{v} \\
 & =\lVert \mathbf{u} \rVert ^{2}+\lVert \mathbf{v} \rVert ^{2}-2\mathbf{u}\cdot \mathbf{v}
\end{align}
$$
Hence
$$
\lVert \mathbf{u} \rVert ^{2}+\lVert \mathbf{v} \rVert ^{2}-2\lVert \mathbf{u} \rVert \lVert \mathbf{v} \rVert \cos\theta =\lVert \mathbf{u} \rVert ^{2}+\lVert \mathbf{v} \rVert ^{2}-2\mathbf{u}\cdot \mathbf{v}
$$
So
$$
\mathbf{u}\cdot \mathbf{v}=\lVert \mathbf{u} \rVert \lVert \mathbf{v} \rVert \cos\theta
$$
$\square$

#### Remarks
1. if $\mathbf{u},\,\mathbf{v}\neq \mathbf{0}$ and $\mathbf{u}\cdot \mathbf{v}=0$, then $\cos\theta=0$. So $\mathbf{u}\cdot \mathbf{v}=0\iff \mathbf{u}$ and $\mathbf{v}$ are perpendicularcular (or orthogonal)
2. Since $|\cos\theta|\leq 1$, we have that $$
|\mathbf{u}\cdot \mathbf{v}|\leq \lVert \mathbf{u} \rVert \lVert \mathbf{v} \rVert
$$
This is called the Cauchy-Schwartz inequality. This holds for all inner product spaces.

${}   {}$