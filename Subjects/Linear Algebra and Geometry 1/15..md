---
tags:
  - linear_algebra1
  - chapter
date: 2023-11-20
---
[[Directory]], [[Linear Algebra and Geometry 1|Subject Directory]]
# Linear Systems
## 
### Example:
$$
\left(\begin{array}{ccc|c}
0 & -3 & 10 & 11 \\
-3 & -2 & 5 & 1 \\
3 & 0 & -5 & -7
\end{array}\right)
$$
Reduces to
$$
\left(\begin{array}{ccc|c}
-3 & -2 & 5 & 1 \\
0 & -3 & 10 & 11 \\
0 & 0 & -\frac{20}{3} & -\frac{40}{3}
\end{array}\right)
$$
Now we use back substitution to solve: 
$$
\begin{align}
-\frac{20}{3}x_{3}=-\frac{40}{3} & \Rightarrow x_{3}=2 \\
-3x_{2}+10x_{3}=11 & \Rightarrow x_{2}=3 \\
-3x_{1}-2x_{2}+5x_{3}=1 & \Rightarrow x_{1}=1
\end{align}
$$
### Example:
Solve the linear system
$$
\left(\begin{array}{ccccc|c}
1 & 2 & 0 & -1 & 0 & 2 \\
0 & 0 & 1 & -3 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 4
\end{array} \right)
$$
Note that all the pivots are 1, and all the numbers above them are 0, so this matrix is *already* in reduced echelon form. We see that ${} x_{1},\, x_{3},\, x_{5} {}$ are pivot variables. Therefore, ${} x_{2},\, x_{4} {}$ are free variables. Now we have
$$
\begin{align}
 x_{5} & =4   \tag1\\
x_{3}-3x_{4} & =1 \tag{2}\\
x_{1}+2x_{2}-x_{4} & =2 \tag{3}
 \end{align}
$$
So this gives
$$
\begin{align}
x_{1} & =2x-2x_{2}+x_{4} \\
x_{2}  & \text{ is free} \\
x_{3} & =1+3x_{4} \\
x_{4} & \text{ is free} \\
x_{5} & = 4
\end{align}
$$
Then if we set ${} x_{2}=t {}$ and ${} x_{4}=s {}$ (for psychological reasons)
$$
\mathbf{x}=\begin{pmatrix} x_{1} \\ x_{2} \\ x_{3} \\ x_{4} \\ x_{5} \end{pmatrix} =\begin{pmatrix} 2-2t+s \\ t \\ 1+3s \\ s \\ 4 \end{pmatrix} =\begin{pmatrix} 2 \\ 0 \\ 1 \\ 0 \\ 4 \end{pmatrix} +t \begin{pmatrix} -2 \\ 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} +s \begin{pmatrix} 1 \\ 0 \\ 3 \\ 1 \\ 0 \end{pmatrix} =\begin{pmatrix}
2 & 0 & 1 & 0 & 4 \\
-2 & 1 & 0 & 0 & 0 \\
1 & 0 & 3 & 1 & 0
\end{pmatrix}
\begin{pmatrix} 1 \\ t \\ s \end{pmatrix} 
$$
Which is the parametric equation for the set of solutions in ${} \mathbb{R}^{5} {}$. Since there are 2 free variables, we call it a *${} 2 {}$-parameter family*. Observe: "non-uniqueness" is due to free variables. 

## Elementary Matrices
If ${} \mathbf{a}_{1},\, \mathbf{a}_{2},\,\dots,\,a_{n} {}$ are rows of $A {}$, then we have
$$
\begin{pmatrix}v_{1} & v_{2} & \dots & v_{n} \end{pmatrix} 
\begin{pmatrix}
\leftarrow  & \mathbf{a}_{1} & \to{} \\
\leftarrow &  \mathbf{a}_{2}  & \to{} \\
 & \vdots &  \\
\leftarrow  &  \mathbf{a}_{n} & \to{}
\end{pmatrix}=v_{1}\mathbf{a}_{1}+v_{2}\mathbf{a}_{2}+\dots+v_{n}\mathbf{a}_{n}
$$
Etc.
### Consequence:
Row Operations are equivalent to left multiplication by a matrix. 
#### Examples:
1. interchange row 1 and row 2
$$
\begin{pmatrix}0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix}\leftarrow & \mathbf{a}_{1} & \to{} \\ \leftarrow & \mathbf{a}_{2} & \to{} \\ \leftarrow & \mathbf{a}_{3} & \to{} \end{pmatrix} 
$$
2. Multiply row 3 by ${} \alpha\neq 0$
$$
\begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & \alpha \end{pmatrix}\begin{pmatrix}\leftarrow & \mathbf{a}_{1} & \to{} \\ \leftarrow & \mathbf{a}_{2} & \to{} \\ \leftarrow & \mathbf{a}_{3} & \to{} \end{pmatrix} 
$$
3. Add $\alpha$ tomes row 1 to row 3
$$
\begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ \alpha & 0 & 1 \end{pmatrix} \begin{pmatrix}\leftarrow & \mathbf{a}_{1} & \to{} \\ \leftarrow & \mathbf{a}_{2} & \to{} \\ \leftarrow & \mathbf{a}_{3} & \to{} \end{pmatrix} 
$$
#### Observation:
The matrix corresponding to some row operation ${} R$ is obtained by applying $R$ to $I$
### Definition 1.1:
A square matrix is elementary if it can be transformed into the identity matrix with *one* elementary row operation.
#### Observation:
Since elementary row operations are reversible, each elementary matrix is invertible. 

Let ${} A {}$ be a matrix. Suppose we can put $A$ into echelon form (or reduced echelon form) by elementary row operations (henceforth ERO) ${} R_{1},\, R_{2},\,\dots,\,\, R_{k}$. Let ${} E_{j} {}$ be the elementary matrix corresponding to $R_{j}$. Then
$$
E_{k}\dots E_{2}E_{1}A
$$
is in echelon form. Let $E=E_{k}\dots E_{2}E_{1}$. Since each ${} E_{j} {}$ is invertible, then $E$ is invertible. 
### Key Idea
Given a matrix $A$, we can always find an invertible matrix $E$ such that $EA$ is in echelon form (or reduced echelon form).
# Invertible Maps
### Proposition 2.1
Let ${} A: \mathbb{F}^{n}\to{}\mathbb{F}^{m}$ (this works for any 2 vector spaces but we use these for simplicity) be a linear map. $A$ is invertible iff ${} A\mathbf{x} =\mathbf{b} {}$ has unique solution for all ${} \mathbf{b} \in \mathbb{F}^{m} {}$.
#### Sketch Proof:
First working ${} (\Rightarrow ) {}$. If $A$ is invertible, $AA^{-1}\mathbf{b}=\mathbf{b}$, so ${} \mathbf{x}=A^{-1}\mathbf{b} {}$ is a solution of ${} A\mathbf{x}=\mathbf{b} {}$. If $\mathbf{x}$ is any solution, then $A^{-1}A\mathbf{x}=A^{-1}\mathbf{b}\quad\Rightarrow\quad \mathbf{x}=A^{-1}\mathbf{b}$.

Now working ${} (\Leftarrow )$. If ${} A\mathbf{x}=\mathbf{b} {}$ has a unique solution for all $\mathbf{b} \in \mathbb{F}^{m}$, set ${} A^{-1}\mathbf{b} {}$ to be the unique solution of ${} A\mathbf{x}=\mathbf{b} {}$. Then $A^{-1} {}$ is linear and ${} A A^{-1}=A^{-1}A=I {}$.
### Proposition 2.2
Let $A {}$ be a linear map. Then the following things are equivalent:
1. $A {}$ is invertible
2. The echelon form of $A {}$ has a pivot in every row and column
3. The reduced echelon form of ${} A {}$ is the identity matrix
### Consequence:
Invertible matrices must be square.
### Computing $A^{-1} {}$
Let $A$ be a ${} n \times  n {}$ matrix, and let $E$ be an invertible matrix $E$ such that ${} EA {}$ is in reduced echelon form.

Observe that $A$ is invertible $\Rightarrow EA=I$, so $E=A^{-1}$. So we have an idea:
We compute with
$$(A \mid I)$$
We row reduce to put $A$ into reduced echelon form, so we get
$$
(EA\mid E)=(I\mid A^{-1})
$$
If we can't do this, then $A$ is *not* invertible.
#### Example:
Let
$$
A=\begin{pmatrix}1 & -1 & 0 \\ 1 & 0 & -2 \\ 1 & -1 & 1 \end{pmatrix} 
$$
We form a augmented matrix and row reduce:
$$
\left( \begin{array}{ccc|ccc}
1 & -1 & 0 & 1 & 0 & 0 \\
1 & 0 & -2 & 0 & 1 & 0 \\
1 & -1 & 1 & 0 & 0 & 1
\end{array} \right) 
\to{\text{ R2-R1, R3-R1}}
\left( \begin{array}{ccc|ccc}
1 & -1 & 0 & 1 & 0 & 0 \\
0 & 1 & -2 & -1 & 1 & 0 \\
0 & 0 & 1 & -1 & 0 & 1
\end{array} \right) 

$$
$$
\to{\text{R2+2R3}}\left( \begin{array}{ccc|ccc}
1 & -1 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & -3 & 1 & 2 \\
0 & 0 & 1 & -1 & 0 & 1
\end{array} \right) 
\to{\text{R1+R2}} \left( \begin{array}{ccc|ccc}
1 & 0 & 0 & -2 & 1 & 2 \\
0 & 1 & 0 & -3 & 1 & 2 \\
0 & 0 & 1 & -1 & 0 & 1
\end{array} \right) 
$$
So therefore ${} A$ is invertible, and
$$
A^{-1}=\begin{pmatrix}-2 & 1 & 2 \\ -3 & 1 & 2 \\ -1 & 0 & 1 \end{pmatrix} 
$$
### Example:
Let
$$
B=\begin{pmatrix}1 & -2 & 0 \\ 2 & -1 & -2 \\ 0 & 3 & -2 \end{pmatrix} 
$$
Then
$$
\left( \begin{array}{ccc|ccc}
1 & -2 & 0 & 1 & 0 & 0 \\
2 & -1 & -2 & 0 & 1 & 0 \\
0 & 3 & -2 & 0 & 0 & 1
\end{array} \right) \to{\text{ R2-2R1}}
\left( \begin{array}{ccc|ccc} 
1 & -2 & 0 & 1 & 0 & 0 \\
0 & 3 & -2 & -2 & 1 & 0 \\
0 & 3 & -2 & 0 & 0 & 1
\end{array} \right) 
$$
$$
\to{\text{ R3-R2}} \left( \begin{array}{ccc|ccc}
1 & -2 & 0 & 1 & 0 & 0 \\
0 & 3 & -2 & -2 & 1 & 0 \\
0 & 0 & 0 & 2 & -1 & 1
\end{array} \right) 
$$
So $B$ is not invertible, as this matrix is in echelon form, but only has 2 pivots