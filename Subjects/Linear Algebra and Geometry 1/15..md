---
tags:
  - linear_algebra1
  - chapter
date: 2023-11-20
---
[[Directory]], [[Linear Algebra and Geometry 1|Subject Directory]]
# Linear Systems
## 
### Example:
$$
\begin{pmatrix}
0 & -3 & 10 & 11 \\
-3 & -2 & 5 & 1 \\
3 & 0 & -5 & -7
\end{pmatrix}
$$
Reduces to
$$
\begin{pmatrix}
-3 & -2 & 5 & 1 \\
0 & -3 & 10 & 11 \\
0 & 0 & -\frac{20}{3} & -\frac{40}{3}
\end{pmatrix}
$$
Now we use back substitution to solve: 
$$
\begin{align}
-\frac{20}{3}x_{3}=-\frac{40}{3} & \Rightarrow x_{3}=2 \\
-3x_{2}+10x_{3}=11 & \Rightarrow x_{2}=3 \\
-3x_{1}-2x_{2}+5x_{3}=1 & \Rightarrow x_{1}=1
\end{align}
$$
### Example:
Solve the linear system
$$
\left(\begin{array}{ccccc|c}
1 & 2 & 0 & -1 & 0 & 2 \\
0 & 0 & 1 & -3 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 4
\end{array} \right)
$$
Note that all the pivots are 1, and all the numbers above them are 0, so this matrix is *already* in reduced echelon form. We see that ${} x_{1},\, x_{3},\, x_{5} {}$ are pivot variables. Therefore, ${} x_{2},\, x_{4} {}$ are free variables. Now we have
$$
\begin{align}
 x_{5} & =4   \tag1\\
x_{3}-3x_{4} & =1 \tag{2}\\
x_{1}+2x_{2}-x_{4} & =2 \tag{3}
 \end{align}
$$
So this gives
$$
\begin{align}
x_{1} & =2x-2x_{2}+x_{4} \\
x_{2}  & \text{ is free} \\
x_{3} & =1+3x_{4} \\
x_{4} & \text{ is free} \\
x_{5} & = 4
\end{align}
$$
Then if we set ${} x_{2}=t {}$ and ${} x_{4}=s {}$ (for psychological reasons)
$$
\mathbf{x}=\begin{pmatrix} x_{1} \\ x_{2} \\ x_{3} \\ x_{4} \\ x_{5} \end{pmatrix} =\begin{pmatrix} 2-2t+s \\ t \\ 1+3s \\ s \\ 4 \end{pmatrix} =\begin{pmatrix} 2 \\ 0 \\ 1 \\ 0 \\ 4 \end{pmatrix} +t \begin{pmatrix} -2 \\ 1 \\ 0 \\ 0 \\ 0 \end{pmatrix} +s \begin{pmatrix} 1 \\ 0 \\ 3 \\ 1 \\ 0 \end{pmatrix} =\begin{pmatrix}
2 & 0 & 1 & 0 & 4 \\
-2 & 1 & 0 & 0 & 0 \\
1 & 0 & 3 & 1 & 0
\end{pmatrix}
\begin{pmatrix} 1 \\ t \\ s \end{pmatrix} 
$$
Which is the parametric equation for the set of solutions in ${} \mathbb{R}^{5} {}$. Since there are 2 free variables, we call it a *${} 2 {}$-parameter family*. Observe: "non-uniqueness" is due to free variables. 

## Elementary Matrices
If ${} \mathbf{a}_{1},\, \mathbf{a}_{2},\,\dots,\,a_{n} {}$ are rows of $A {}$, then we have
$$
\begin{pmatrix}v_{1} & v_{2} & \dots & v_{n} \end{pmatrix} 
\begin{pmatrix}
\leftarrow  & \mathbf{a}_{1} & \to{} \\
\leftarrow &  \mathbf{a}_{2}  & \to{} \\
 & \vdots &  \\
\leftarrow  &  \mathbf{a}_{n} & \to{}
\end{pmatrix}=v_{1}\mathbf{a}_{1}+v_{2}\mathbf{a}_{2}+\dots+v_{n}\mathbf{a}_{n}
$$
Etc.
### Consequence:
Row Operations are equivalent to left multiplication by a matrix. 
#### Examples:
1. interchange row 1 and row 2
$$
\begin{pmatrix}0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix}\leftarrow & \mathbf{a}_{1} & \to{} \\ \leftarrow & \mathbf{a}_{2} & \to{} \\ \leftarrow & \mathbf{a}_{3} & \to{} \end{pmatrix} 
$$
2. Multiply row 3 by ${} \alpha\neq 0$
$$
\begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & \alpha \end{pmatrix}\begin{pmatrix}\leftarrow & \mathbf{a}_{1} & \to{} \\ \leftarrow & \mathbf{a}_{2} & \to{} \\ \leftarrow & \mathbf{a}_{3} & \to{} \end{pmatrix} 
$$
3. Add $\alpha$ tomes row 1 to row 3
$$
\begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ \alpha & 0 & 1 \end{pmatrix} \begin{pmatrix}\leftarrow & \mathbf{a}_{1} & \to{} \\ \leftarrow & \mathbf{a}_{2} & \to{} \\ \leftarrow & \mathbf{a}_{3} & \to{} \end{pmatrix} 
$$
#### Observation:
The matrix corresponding to some row operation ${} R$ is obtained by applying $R$ to $I$
### Definition 1.1:
A square matrix is elementary if it can be transformed into the identity matrix with *one* elementary row operation.
#### Observation:
Since elementary row operations are reversible, each elementary matrix is invertible. 
