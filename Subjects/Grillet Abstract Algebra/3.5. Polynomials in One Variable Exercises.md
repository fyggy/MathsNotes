---
tags:
  - exercises
  - grillet_abstract_alg
date:
count: 25
---
[[Directory]], [[Grillet Abstract Algebra]]
[[3.4. Domains and Fields Exercises.md|Last]] ;; [[3.6. Polynomials in Several Variables Exercises.md|Next]]
1. skip
2. skip
3. 
Let ${} n=\deg A {}$. First note that if ${} n=0 {}$, then $A {}$ is a constant, and we may write ${} A=A + B \cdot 0 +B^{2} \cdot  0 +\dots_{} {}$. Since ${} \deg B \geq 1 {}$, then ${} \deg A < \deg  B$. Now suppose that the proposition holds for ${} n\leq k {}$. Now if ${} \deg A=k+1 {}$
$$
A=Q B + S
$$
where ${} \deg S< \deg  B {}$, and ${} \deg Q < \deg A=k+1 {}$, since ${} \deg B \geq 1 {}$. Therefore, we may write $Q$ as
$$
Q=\sum_{i=0}^{\deg Q} Q_{i} B^{i} 
$$
and so setting ${} R_{0}=S {}$ and ${} R_{i+1}=Q_{i} {}$
$$
A=\left(\sum_{i=0}^{\deg Q} Q_{i} B^{i} \right)B + S=\sum_{i=0}^{\deg  Q+1}R_{i} B^{i} 
$$
4. 
Let $R \leq S {}$ be a subring. Let ${} s \in S {}$, and suppose that ${} e:R[X]\to{}S {}$ with ${} e(P)=P(s) {}$ is a homomorphism. Now we have, corresponding to every element ${} r {}$ of ${} R {}$, a polynomial $rX$. Evaluating at this polynomial, we see that
$$
e(X)e(r)=sr=rs=e(rX)=e(X \cdot r)
$$
and so $s$ commutes with every element of $R$. Conversely, we have already seen that if $s$ commutes with every element of $R$, then $e$ is a homomorphism
5. skip
6. 
Let $M$ be a maximal ideal of $R$. Now suppose that $J\geq M+(X) {}$ is an ideal. Now if ${} A \in J$ and ${} A \notin M +(X) {}$, then the constant term $a_{0} {}$ of $A {}$ is not element of ${} M {}$. This implies that the smallest ideal containing $a_{0}$ and $M$ is $R$, and so $J$ contains $R$. But $J$ also contains all polynomials with constant term $0$, so $J=R[X] {}$, and $M+(X)$ is maximal.
7. skip
8. skip
9. skip
10. 
Let $R {}$ be a commutative ring with ${} c=\Char R {}$ with $c>m {}$ or ${} c=0 {}$. Let ${} A \in R[X] {}$, and let $r$ be a root of $A$. Now suppose that $r$ has multiplicity $m$. Then we may write
$$
A=B(X-r)^{m}
$$
where ${} B(r)\neq 0 {}$, and so if $k<m {}$, we have
$$
A^{(k)}=\sum_{i=0}^{k} \binom{k}{i} B^{(k-i)}((X-r)^{m}) ^{(i)}
$$
since ${} i\leq k<m {}$, we have that ${} X-r \mid A^{(k)} {}$, and so ${} A^{(k)}(r)=0 {}$. However we have
$$
\begin{align}
 A^{(m)} & =\sum_{i=0}^{m} \binom{m}{i} B^{(m-i)}((X-r)^{m}) ^{(i)}   \\
 & =m!B+\sum_{i=0}^{m-1} \binom{m}{i} B^{(m-i)}((X-r)^{m}) ^{(i)}
 \end{align}
$$
and so since $m!\neq 0 {}$, then ${} A^{(m)}(r)=m! B(r)\neq 0 {}$. 

Conversely, suppose that ${} A^{(k)}(r)=0 {}$ for $k<m {}$, and ${} A^{(m)}(r)\neq 0 {}$. Therefore, if $r {}$ is a root of $A {}$, we may write ${} A=(X-r)B {}$. Since ${} \deg B<\deg A {}$, and if ${} \deg A=1 {}$, then ${} A=(X-r) {}$ and so we saw that the hypothesis holds for this case. Therefore, we may assume by induction that the hypothesis holds for ${} B {}$ by inducting on degree. 

Now if ${} n <m {}$, 
$$
0= A  ^{(n)}(r)=\left( \sum_{i=0}^{n} \binom{n}{i} (X-r)^{(i)} B^{(n-i)} \right)(r)=\left((X-r)B^{(n)}\right)(r)+n B^{(n-1)}(r)
$$
and so since ${} n<c {}$, and $n\neq 0$, then ${} B^{(n-1)}(r)=0 {}$. Furthermore, we have that if ${} n=m {}$
$$
0\neq A  ^{(n)}(r)=\left( \sum_{i=0}^{n} \binom{n}{i} (X-r)^{(i)} B^{(n-i)} \right)(r)=\left((X-r)B^{(n)}\right)(r)+n B^{(n-1)}(r)
$$
and so ${} B^{(m-1)}\neq 0 {}$. Therefore, ${} B=(X-r)^{m-1}C_{k} {}$ and so ${} A=(X-r)^{m} C_{k} {}$. 
11. skip
12. skip
13. skip
14. 
Let ${} B \in R[X] {}$ and define ${} \varphi:R[X]\to{}R[X] {}$ by ${} \varphi_{B}(A)=A \circ  B {}$. First suppose that ${} \varphi_{B} {}$ is a homomorphism for every ${} B {}$. Then given ${} a,\, b \in R {}$, set ${} B=b {}$, and 
$$
\varphi(aX)=ab =ba=\varphi(X)\varphi(a)=\varphi(X \cdot  a)
$$
and so $R$ is commutative.

Conversely, suppose that $R$ is commutative. Now ${} \varphi_{B}(A)=A \circ  B {}$, so
$$
\begin{align}
 \varphi_{B}(X+Y) & =(X+Y) \circ  B   \\
 &= \sum_{i=0}^{k}(x_{i}+y_{i})B^{i} \\
 & =\sum_{i=0}^{k} x_{i}B^{i}+\sum_{i=0}^{k} y_{i} B^{i} \\
 & =\varphi_{B}(X)+\varphi_{B}(Y)
 \end{align}
$$
and
$$
\begin{align}
\varphi_{B}(X) \varphi_{B}(Y) & =\left( \sum_{i=0}^{k_{1}}x_{i} B^{i} \right)\left( \sum_{i=0}^{k_{2}} y_{i} B^{i} \right) \\
 & = \sum_{i=0}^{k_{1}} \sum_{j=0}^{k_{2}}x_{i} B^{i} y_{j} B^{j} \\
 & =\sum_{n=0}^{k_{1}+k_{2}} \sum_{i+j=n} x_{i}y_{j} B^{n} \\
 & =\varphi_{B}(XY)
\end{align}
$$
15. skip
16. skip
17. 
Let $\varphi :R\to{}S {}$, and let $v:M\to{}S {}$ be a multiplicative homomorphism of monoids such that every element of $\im v$ commutes with every element of every element of $\im \varphi$. Then there exists a unique homomorphism $\psi:R[M]\to{}S {}$ such that, given ${} A \in R[M] {}$, we have
$$
A=\sum_{i \in I} a_{i} X_{i} 
$$
where ${} X_{i} \in M {}$, and
$$
\psi(A)=\sum_{i \in I} \varphi(a_{i}) v(X_{i})
$$
and so $\psi$ extends $\varphi$.